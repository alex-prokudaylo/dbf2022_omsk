{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport time\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data import RandomSampler\n\nimport torchvision.transforms as T\nimport torchvision.models as models\nfrom torchvision.utils import make_grid\nfrom torchvision.datasets import ImageFolder\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom xml.etree import ElementTree as et\n#from torch_snippets import *\n\nfrom IPython import display \ndisplay.set_matplotlib_formats('svg')\n\nfrom PIL import Image\nfrom PIL import ImageFont, ImageDraw\n\nfrom tqdm import tqdm\n\nfrom torchvision.ops import box_iou\nimport albumentations as A\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-20T13:04:06.652095Z","iopub.execute_input":"2022-10-20T13:04:06.652599Z","iopub.status.idle":"2022-10-20T13:04:08.687391Z","shell.execute_reply.started":"2022-10-20T13:04:06.65248Z","shell.execute_reply":"2022-10-20T13:04:08.68636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(\"../input/dbf-omsk-dataset/train_dataset_train/train.csv\")\ntrain_data_plus = train_data[train_data.count_region > 0]\ntrain_data_plus","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:04:08.692301Z","iopub.execute_input":"2022-10-20T13:04:08.694813Z","iopub.status.idle":"2022-10-20T13:04:08.804229Z","shell.execute_reply.started":"2022-10-20T13:04:08.694766Z","shell.execute_reply":"2022-10-20T13:04:08.802693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_data","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:04:08.805674Z","iopub.execute_input":"2022-10-20T13:04:08.808283Z","iopub.status.idle":"2022-10-20T13:04:08.814203Z","shell.execute_reply.started":"2022-10-20T13:04:08.808236Z","shell.execute_reply":"2022-10-20T13:04:08.812659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ast\n\ndef parse_region_shape(region_shape_str, image_id=0):\n    data = ast.literal_eval(region_shape_str)\n    \n    list_with_all_boxes = []\n    \n    for box in data:\n        box_dict = ast.literal_eval(box)\n        #print(box_dict[\"cx\"])\n        # The COCO bounding box format is [top left x position, top left y position, width, height]\n        coco_xmin = box_dict[\"cx\"] - box_dict[\"r\"] \n        coco_ymin = box_dict[\"cy\"] - box_dict[\"r\"] \n        coco_width = 2 * box_dict[\"r\"] \n        coco_height = 2 * box_dict[\"r\"] \n    \n        coco_list_with_single_boxes = [coco_xmin, coco_ymin, coco_width, coco_height]\n    \n        line = {'category_id': 1.0, 'bbox': coco_list_with_single_boxes, 'area': 1.0}\n        list_with_all_boxes.append(line)\n\n\n    return list_with_all_boxes\n\nregion_shape_sample = train_data_plus.region_shape.values[5]\nparse_region_shape(region_shape_sample)","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:04:08.825867Z","iopub.execute_input":"2022-10-20T13:04:08.826266Z","iopub.status.idle":"2022-10-20T13:04:08.844438Z","shell.execute_reply.started":"2022-10-20T13:04:08.826227Z","shell.execute_reply":"2022-10-20T13:04:08.843527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ntransform = A.Compose([\n    A.RandomCrop(width=450, height=450),\n    A.HorizontalFlip(p=0.5),\n    A.RandomBrightnessContrast(p=0.2),\n], bbox_params=A.BboxParams(format='coco'))\n\ntransformed = transform(image=image, bboxes=bboxes, class_labels=class_labels)\ntransformed_image = transformed['image']\ntransformed_bboxes = transformed['bboxes']\n\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset): \n    def __init__(self, file_dir, file_list, box_str_list = None, feature_extractor=None): \n        self.file_dir = file_dir\n        self.file_list = file_list\n        self.box_list = box_str_list\n        self.feature_extractor = feature_extractor\n        \n    def __len__(self): \n        return len(self.file_list)\n    \n    def __getitem__(self, index): \n        \n        #if self.file_list[index] == \"2050.DS_Store\":\n        #    image_path = \"../input/dbf-omsk-dataset/test_dataset_test/test/0.JPG\"\n        #else:\n        image_path = self.file_dir + self.file_list[index]  \n        box_str = self.box_list[index]  \n        \n        image_res = Image.open(image_path).convert('RGB')#.resize(self.width, self.height)        \n        \n        #wt = image_res.shape[1]\n        #ht = image_res.shape[0]     \n        \n        target = {}\n        \n        target['annotations'] = parse_region_shape(box_str)\n\n        target['image_id'] = index \n        \n        if self.feature_extractor:\n            return feature_extractor(images=image_res, annotations=target, return_tensors=\"pt\")\n        else:\n            return image_res, target","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:04:08.848296Z","iopub.execute_input":"2022-10-20T13:04:08.851082Z","iopub.status.idle":"2022-10-20T13:04:08.860539Z","shell.execute_reply.started":"2022-10-20T13:04:08.851045Z","shell.execute_reply":"2022-10-20T13:04:08.859657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoFeatureExtractor\n\nfeature_extractor = AutoFeatureExtractor.from_pretrained(\"hustvl/yolos-base\", size=512, max_size=768)","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:04:08.863974Z","iopub.execute_input":"2022-10-20T13:04:08.8643Z","iopub.status.idle":"2022-10-20T13:04:10.268181Z","shell.execute_reply.started":"2022-10-20T13:04:08.864256Z","shell.execute_reply":"2022-10-20T13:04:10.267292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"../input/dbf-omsk-test2/sample_solution.csv\")\ntest_df = test_df.drop([\"count_region\"], axis = 1)\ntest_df.ID_img.values","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:04:10.272114Z","iopub.execute_input":"2022-10-20T13:04:10.272753Z","iopub.status.idle":"2022-10-20T13:04:10.302914Z","shell.execute_reply.started":"2022-10-20T13:04:10.2727Z","shell.execute_reply":"2022-10-20T13:04:10.30193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_dir_train = '../input/dbf-omsk-dataset/train_dataset_train/train/'\nfile_dir_test = '../input/dbf-omsk-test2/test_dataset_test/test/'\n\nfiles_test = list(test_df.ID_img.values)\n#os.listdir(file_dir_test) \nfiles_train = train_data_plus[\"ID_img\"].values\n\ntest_boxed_dimmy = [\"[ ]\" for i in files_test]","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:04:10.307524Z","iopub.execute_input":"2022-10-20T13:04:10.309926Z","iopub.status.idle":"2022-10-20T13:04:10.317496Z","shell.execute_reply.started":"2022-10-20T13:04:10.30989Z","shell.execute_reply":"2022-10-20T13:04:10.316592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Getting the dataset \ntrain_set = CustomDataset(file_dir_train, files_train, train_data_plus.region_shape.values, feature_extractor=feature_extractor)\ntest_set = CustomDataset(file_dir_test, files_test, test_boxed_dimmy, feature_extractor=feature_extractor)\n\nprint(len(train_set), len(test_set))\n\n\n# Data Loader \ntrain_dataloader = DataLoader(train_set, batch_size = 1, shuffle = True, num_workers = 1)\ntest_loader = DataLoader(test_set, batch_size = 1, shuffle = False, num_workers = 1)","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:04:10.321933Z","iopub.execute_input":"2022-10-20T13:04:10.324782Z","iopub.status.idle":"2022-10-20T13:04:10.336556Z","shell.execute_reply.started":"2022-10-20T13:04:10.324716Z","shell.execute_reply":"2022-10-20T13:04:10.335569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tensor = train_set[9]['pixel_values'][0]\nboxes = train_set[9]['labels'][0]['boxes']\n\ntensor = 0.225 * tensor + 0.456\n\nimg = T.ToPILImage()(tensor)\n\nprint(img.size)\nplt.figure(figsize=(20, 20))\n\ndraw = ImageDraw.Draw(img)\nfor box in boxes:\n    print(box)\n    x1, y1, w_size, h_size = box[0], box[1], box[2], box[3] \n    x_start = (x1 - (w_size/2)) * img.size[0]\n    y_start = (y1 - (h_size/2)) * img.size[1]\n    x_end = (x_start + w_size * img.size[0]) \n    y_end = (y_start + h_size * img.size[1]) \n    print(x_start, y_start, x_end, y_end)\n    #draw.rectangle(((x_start, y_start), (x_end, y_end)), outline =\"red\")\n    draw.ellipse(((x_start, y_start), (x_end, y_end)), outline =\"red\")\n    \nplt.imshow(img)\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:04:10.344399Z","iopub.execute_input":"2022-10-20T13:04:10.346638Z","iopub.status.idle":"2022-10-20T13:04:12.364755Z","shell.execute_reply.started":"2022-10-20T13:04:10.346604Z","shell.execute_reply":"2022-10-20T13:04:12.361794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DetrConfig, AutoModelForObjectDetection\n\n#model = Detr(lr=2.5e-5, weight_decay=1e-4)\nmodel = AutoModelForObjectDetection.from_pretrained(\"hustvl/yolos-base\", num_labels=3, ignore_mismatched_sizes=True)\n#'hustvl/yolos-base'  \"hustvl/yolos-small\"\nlr=2.5e-5\nweight_decay=1e-4\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:04:12.365988Z","iopub.execute_input":"2022-10-20T13:04:12.366317Z","iopub.status.idle":"2022-10-20T13:04:25.883885Z","shell.execute_reply.started":"2022-10-20T13:04:12.366286Z","shell.execute_reply":"2022-10-20T13:04:25.882847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():  \n    model.cuda()","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:04:25.885742Z","iopub.execute_input":"2022-10-20T13:04:25.886552Z","iopub.status.idle":"2022-10-20T13:04:29.080081Z","shell.execute_reply.started":"2022-10-20T13:04:25.886507Z","shell.execute_reply":"2022-10-20T13:04:29.078429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load(f\"../input/dbfmodelkrasnodar-v2/model_krasnodar.pth\"), strict=False)","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:04:29.082065Z","iopub.execute_input":"2022-10-20T13:04:29.082428Z","iopub.status.idle":"2022-10-20T13:04:35.389614Z","shell.execute_reply.started":"2022-10-20T13:04:29.082391Z","shell.execute_reply":"2022-10-20T13:04:35.388724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set[7]['labels'][0]['boxes']","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:04:35.391185Z","iopub.execute_input":"2022-10-20T13:04:35.39157Z","iopub.status.idle":"2022-10-20T13:04:35.865901Z","shell.execute_reply.started":"2022-10-20T13:04:35.391533Z","shell.execute_reply":"2022-10-20T13:04:35.864794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def yolo_box2xy(box):\n    \n        x1, y1, w_size, h_size = box[:,0], box[:,1], box[:,2], box[:,3] \n        \n        # для рисования\n        x_start = (x1 - (w_size/2))\n        y_start = (y1 - (h_size/2)) \n        x_end = (x_start + w_size ) \n        y_end = (y_start + h_size )\n        #print(x_start)\n        xy = torch.stack((x_start, y_start, x_end, y_end)).permute(1,0)\n        return xy\n        \nyolo_box2xy(train_set[7]['labels'][0]['boxes'])","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:04:35.86743Z","iopub.execute_input":"2022-10-20T13:04:35.869394Z","iopub.status.idle":"2022-10-20T13:04:36.267058Z","shell.execute_reply.started":"2022-10-20T13:04:35.869352Z","shell.execute_reply":"2022-10-20T13:04:36.266039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch_num in range(0):\n    train_loss = 0\n    train_loss_ce = 0\n    train_loss_bbox = 0\n    valid_loss = 0\n    valid_loss_ce = 0\n    valid_loss_bbox = 0\n    \n    valid_box_iou = 0\n    loss = 0\n    \n    # Train loop   \n    model.train()\n    #print(\"Train step\")\n    for ii, batch in enumerate(iter(train_dataloader)):\n        #print(batch[\"labels\"])\n        pixel_values = batch['pixel_values'][0]\n        \n        if torch.cuda.is_available():\n            pixel_values = pixel_values.cuda()\n            \n\n        if torch.cuda.is_available():  \n            labels = [{k: v[0].cuda() for k, v in t.items()} for t in batch['labels']]\n        else:\n            labels = [{k: v[0] for k, v in t.items()} for t in batch['labels']]\n        \n        #print(labels)\n        \n        outputs = model(pixel_values=pixel_values, labels=labels)\n        \n        #print(outputs)\n\n        loss += outputs.loss\n        if (ii+1)%4 == 0:       \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            loss = 0\n        \n        #train_loss += loss.item()\n        train_loss_ce += outputs.loss_dict['loss_ce'].item()\n        train_loss_bbox += outputs.loss_dict['loss_bbox'].item()\n        \n \n        boxes1 = yolo_box2xy(labels[0]['boxes'].cpu().detach())\n        boxes2 = yolo_box2xy(outputs.pred_boxes[0].cpu().detach())\n\n        valid_box_iou += torch.sum(box_iou(boxes1, boxes2))\n\n        \n        #break\n    #break\n        #if ii%10 == 0:\n        #    print(\"Iter {}, Loss = {:.4f} {:.4f} {:.4f}\".format(ii, loss.item(), outputs.loss_dict['loss_ce'].item(), outputs.loss_dict['loss_bbox'].item()))\n\n    # Valid loop \n    '''\n    model.eval()\n    #print(\"Eval step\")\n    for ii, batch in enumerate(iter(val_dataloader)):\n        \n        if torch.cuda.is_available():\n            pixel_values = pixel_values.cuda()\n        \n        if torch.cuda.is_available():  \n            labels = [{k: v[0].cuda() for k, v in t.items()} for t in batch['labels']]\n        else:\n            labels = [{k: v[0] for k, v in t.items()} for t in batch['labels']]\n        \n        outputs = model(pixel_values=pixel_values, labels=labels)\n\n        #loss = outputs.loss\n        \n        #valid_loss += loss.item()\n        valid_loss_ce += outputs.loss_dict['loss_ce'].item()\n        valid_loss_bbox += outputs.loss_dict['loss_bbox'].item()\n    '''\n    #valid_box_iou = valid_box_iou / \n    print(\"Epoch {}, Train loss CE={:.4f}, BBOX={:.4f}, IoU={:.2f}\".format(epoch_num+1, train_loss_ce, train_loss_bbox, valid_box_iou))\n    #print(\"Epoch {}, Valid loss CE={:.4f}, BBOX={:.4f}\".format(epoch_num+1, valid_loss, valid_loss_ce, valid_loss_bbox))","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:08:42.202475Z","iopub.execute_input":"2022-10-20T13:08:42.202852Z","iopub.status.idle":"2022-10-20T13:23:52.823612Z","shell.execute_reply.started":"2022-10-20T13:08:42.20282Z","shell.execute_reply":"2022-10-20T13:23:52.821798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#torch.save(model.state_dict(), f\"model_krasnodar.pth\")\n","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:06:40.983209Z","iopub.execute_input":"2022-10-20T13:06:40.98367Z","iopub.status.idle":"2022-10-20T13:06:41.846605Z","shell.execute_reply.started":"2022-10-20T13:06:40.983624Z","shell.execute_reply":"2022-10-20T13:06:41.845627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_pred(i, set, thr=0.8):\n    batch = set[i]\n    pixel_values = batch['pixel_values']#[0]\n    outputs = model(pixel_values=pixel_values.cuda())\n\n    #outputs\n    print(batch['labels'])\n\n    outputs_softmax = torch.softmax(outputs.logits.detach(), dim=-1)[0, :, :-1]\n    probs = torch.max(outputs_softmax, dim=-1).values.cpu()\n    pred_class = torch.max(outputs_softmax, dim=-1).indices.cpu()\n\n    tensor = pixel_values[0].cpu()\n    boxes = outputs.pred_boxes[0].cpu().detach().numpy()\n\n    tensor = 0.225 * tensor + 0.456\n\n    img = T.ToPILImage()(tensor)\n\n    print(img.size)\n    plt.figure(figsize=(15, 15))\n\n    draw = ImageDraw.Draw(img)\n    for n, box in enumerate(boxes):\n        #print(box)\n        x1, y1, w_size, h_size = box[0], box[1], box[2], box[3] \n        x_start = (x1 - (w_size/2)) * img.size[0]\n        y_start = (y1 - (h_size/2)) * img.size[1]\n        x_end = (x_start + w_size * img.size[0]) \n        y_end = (y_start + h_size * img.size[1]) \n\n        if probs[n]>thr:\n            print(n, int(x_start), int(y_start), int(x_end), int(y_end), probs[n].numpy(), pred_class[n].numpy())\n            draw.ellipse(((x_start, y_start), (x_end, y_end)), outline =\"red\")\n\n    plt.imshow(img)\n    plt.axis('off')\n    plt.show()\n    \ntest_pred(9, train_set)","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:06:41.848109Z","iopub.execute_input":"2022-10-20T13:06:41.849153Z","iopub.status.idle":"2022-10-20T13:06:42.958837Z","shell.execute_reply.started":"2022-10-20T13:06:41.849115Z","shell.execute_reply":"2022-10-20T13:06:42.958009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred(0, train_set)","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:06:42.960234Z","iopub.execute_input":"2022-10-20T13:06:42.960955Z","iopub.status.idle":"2022-10-20T13:06:44.192706Z","shell.execute_reply.started":"2022-10-20T13:06:42.960918Z","shell.execute_reply":"2022-10-20T13:06:44.191376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred(5, train_set)","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:06:44.194931Z","iopub.execute_input":"2022-10-20T13:06:44.195336Z","iopub.status.idle":"2022-10-20T13:06:45.548999Z","shell.execute_reply.started":"2022-10-20T13:06:44.195274Z","shell.execute_reply":"2022-10-20T13:06:45.547082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred(12, train_set)","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:06:45.550801Z","iopub.execute_input":"2022-10-20T13:06:45.55184Z","iopub.status.idle":"2022-10-20T13:06:46.756391Z","shell.execute_reply.started":"2022-10-20T13:06:45.551802Z","shell.execute_reply":"2022-10-20T13:06:46.755541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test","metadata":{}},{"cell_type":"code","source":"model.eval()\npredicts = []\n\nthr = 0.85\n\nfor i, batch in enumerate(test_set):\n    #i = files_test.index(\"1275.JPG\")\n    #batch = test_set[i]\n    \n    #if files_test[i] == \"2050.DS_Store\":\n    #    img_path = \"../input/dbf-omsk-dataset/test_dataset_test/test/0.JPG\"\n    #else:\n    #    \n    img_path = file_dir_test + files_test[i]\n    img = Image.open(img_path)\n    \n    if img.size[1] < 1000:\n        predicts.append(0)\n        continue\n    \n    pixel_values = batch['pixel_values']#[0]\n    outputs = model(pixel_values=pixel_values.cuda())\n\n    #outputs\n    #print(batch['labels'])\n\n    outputs_softmax = torch.softmax(outputs.logits.detach(), dim=-1)[0, :, :-1]\n    probs = torch.max(outputs_softmax, dim=-1).values.cpu()\n    pred_class = torch.max(outputs_softmax, dim=-1).indices.cpu()\n\n    #tensor = pixel_values[0].cpu()\n    boxes = outputs.pred_boxes[0].cpu().detach().numpy()\n\n    #tensor = 0.225 * tensor + 0.456\n\n    #img = T.ToPILImage()(tensor)\n\n\n    #print(img.size)\n    \n\n    draw = ImageDraw.Draw(img)\n    \n    pred_lines = []\n    pred_str = \"\"\n    for n, box in enumerate(boxes):\n        #print(box)\n        x1, y1, w_size, h_size = box[0], box[1], box[2], box[3] \n        \n        # для рисования\n        x_start = (x1 - (w_size/2)) * img.size[0]\n        y_start = (y1 - (h_size/2)) * img.size[1]\n        x_end = (x_start + w_size * img.size[0]) \n        y_end = (y_start + h_size * img.size[1]) \n        \n        # для предикта\n        cx = int(x1 * img.size[0])\n        cy = int(y1 * img.size[1])\n        r = min(int((w_size / 2) * img.size[0]), int((h_size / 2) * img.size[1]))\n        \n        if r > cy: r = cy - 1\n        if r > cx: r = cx - 1    \n        if r > img.size[0] - cx: r = img.size[0] - cx - 1 \n        if r > img.size[1] - cy: r = img.size[1] - cy - 1 \n        \n        # Убираем предикты с малым радиусом\n        if (r < 30):\n            continue\n        \n        # берем предикты больше порога\n        if probs[n]>thr:\n            #print(n, int(x_start), int(y_start), int(x_end), int(y_end), probs[n].numpy(), pred_class[n].numpy())\n            pred_line = '{\"cx\":'+str(cx)+ ', \"cy\":'+ str(cy) + ', \"r\":' + str(r)+ '}'\n            #pred_line = '\\'{\"cx\":'+str(0)+ ', \"cy\":'+ str(0) + ', \"r\":' + str(0)+ \"}\\', \"\n            #print(pred_line)\n            pred_lines.append(pred_line)\n            draw.ellipse(((x_start, y_start), (x_end, y_end)), outline =\"red\", width=5)\n            \n        #if(len(pred_lines) == 5): break\n\n    if len(pred_lines) == 0:\n        predicts.append(0)\n    else:\n        #pred_str = \"[\"\n        #for item in pred_lines:\n        #    pred_str += item\n        #pred_str = pred_str[:-2]\n        #pred_str += \"]\"\n        #print(pred_str)\n        predicts.append(pred_lines)\n        \n        plt.figure(figsize=(10, 10))\n        plt.imshow(img)\n        plt.axis('off')\n        plt.show()\n    \n    print(i, files_test[i], img.size[0], img.size[1], len(pred_lines), pred_lines)\n\n    \n\n","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:06:46.758314Z","iopub.execute_input":"2022-10-20T13:06:46.758932Z","iopub.status.idle":"2022-10-20T13:08:38.498609Z","shell.execute_reply.started":"2022-10-20T13:06:46.758894Z","shell.execute_reply":"2022-10-20T13:08:38.496839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(predicts), test_df.shape[0]\n#predicts[3061]\n#predicts.index(['{\"cx\":3473, \"cy\":2322, \"r\":79}', '{\"cx\":3378, \"cy\":2308, \"r\":92}', '{\"cx\":3372, \"cy\":2194, \"r\":91}'])","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:08:38.500159Z","iopub.status.idle":"2022-10-20T13:08:38.50115Z","shell.execute_reply.started":"2022-10-20T13:08:38.500832Z","shell.execute_reply":"2022-10-20T13:08:38.50086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[\"region_shape\"] = predicts #[predicts[3061] for k in range(test_df.shape[0])]\n\nlen(test_df[test_df.region_shape != 0].index)","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:08:38.502848Z","iopub.status.idle":"2022-10-20T13:08:38.503625Z","shell.execute_reply.started":"2022-10-20T13:08:38.503363Z","shell.execute_reply":"2022-10-20T13:08:38.503389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicts[3383]","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:08:38.505056Z","iopub.status.idle":"2022-10-20T13:08:38.505844Z","shell.execute_reply.started":"2022-10-20T13:08:38.505554Z","shell.execute_reply":"2022-10-20T13:08:38.505578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for idx in test_df[test_df.region_shape != 0].index:\n#for idx in test_df.index:\n#    test_df.loc[idx, \"region_shape\"] = ['{\"cx\":300, \"cy\":300, \"r\":100}' for x in range(2)]","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:08:38.507354Z","iopub.status.idle":"2022-10-20T13:08:38.508173Z","shell.execute_reply.started":"2022-10-20T13:08:38.507916Z","shell.execute_reply":"2022-10-20T13:08:38.507941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[test_df.region_shape != 0]","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:08:38.509725Z","iopub.status.idle":"2022-10-20T13:08:38.510497Z","shell.execute_reply.started":"2022-10-20T13:08:38.510244Z","shell.execute_reply":"2022-10-20T13:08:38.510269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.to_csv(\"submit80.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-10-20T13:08:38.511991Z","iopub.status.idle":"2022-10-20T13:08:38.512845Z","shell.execute_reply.started":"2022-10-20T13:08:38.512569Z","shell.execute_reply":"2022-10-20T13:08:38.512593Z"},"trusted":true},"execution_count":null,"outputs":[]}]}